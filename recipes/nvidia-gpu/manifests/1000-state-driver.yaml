apiVersion: v1
kind: ServiceAccount
metadata:
  name: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
  namespace: openshift-sro
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
  namespace: openshift-sro
rules:
- apiGroups:
  - security.openshift.io
  resources:
  - securitycontextconstraints
  verbs:
  - use
  resourceNames:
  - privileged
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
  namespace: openshift-sro
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
  namespace: openshift-sro
subjects:
- kind: ServiceAccount
  name: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
  namespace: openshift-sro
userNames:
- system:serviceaccount:openshift-sro:specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE-entrypoint
  namespace: openshift-sro
data:
  entrypoint.sh: |-
    #!/bin/bash
    LOG_FILE=/tmp/nvidia-driver-log

    nvidia-driver init | tee $LOG_FILE 2>&1 &

    while [ $? -ne 0 ]
    do 
            grep  "+ wait [0-9]*" $LOG_FILE
    done 

    touch /tmp/nvidia-driver-ready

    wait
---
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
allowHostDirVolumePlugin: true
allowHostIPC: false
allowHostNetwork: false
allowHostPID: true
allowHostPorts: false
allowPrivilegeEscalation: true
allowPrivilegedContainer: true
allowedCapabilities:
- '*'
allowedUnsafeSysctls:
- '*'
apiVersion: security.openshift.io/v1
defaultAddCapabilities: null
fsGroup:
  type: RunAsAny
groups:
- system:cluster-admins
- system:nodes
- system:masters
kind: SecurityContextConstraints
metadata:
  annotations:
    kubernetes.io/description: 'privileged allows access to all privileged and host
      features and the ability to run as any user, any group, any fsGroup, and with
      any SELinux context.  WARNING: this is the most relaxed SCC and should be used
      only for cluster administration. Grant with caution.'

  name: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
priority: null
readOnlyRootFilesystem: false
requiredDropCapabilities: null
runAsUser:
  type: RunAsAny
seLinuxContext:
  type: RunAsAny
seccompProfiles:
- '*'
supplementalGroups:
  type: RunAsAny
users:
- system:serviceaccount:openshift-sro:specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
volumes:
- '*'
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
  name: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
  namespace: openshift-sro
  annotations:
    openshift.io/scc: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
    specialresource.openshift.io/wait: "true"
    specialresrouce.openshift.io/wait-for-logs: "\\+ wait \\d+|\\+ sleep infinity"
    specialresource.openshift.io/inject-runtime-info: "true"
    specialresource.openshift.io/state: "driver-container"
    specialresource.openshift.io/driver-container-vendor: SPECIALRESOURCE.OPENSHIFT.IO.NODEFEATURE    
spec:
  selector:
    matchLabels:
      app: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
  template:
    metadata:
      # Mark this pod as a critical add-on; when enabled, the critical add-on scheduler
      # reserves resources for critical add-on pods so that they can be rescheduled after
      # a failure.  This annotation works in tandem with the toleration below.
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ""
      labels:
        app: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
    spec:
      tolerations:
      - operator: Exists
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      serviceAccount: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
      serviceAccountName: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
      hostPID: true
      containers:
      - image: image-registry.openshift-image-registry.svc:5000/openshift-sro/specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE:vSPECIALRESOURCE.OPENSHIFT.IO.KERNELVERSION
        imagePullPolicy: Always
        name: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE-ctr
        command: ["/bin/entrypoint.sh"]
        securityContext:
          privileged: true
          seLinuxOptions:
            level: "s0"
        volumeMounts:
          - name: run-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
            mountPath: /run/nvidia
            mountPropagation: Bidirectional
          - name: entrypoint
            mountPath: /bin/entrypoint.sh
            readOnly: true
            subPath: entrypoint.sh
        livenessProbe: 
          exec: 
            command:
            - cat 
            - /tmp/nvidia-driver-ready 
          failureThreshold: 60
          periodSeconds: 10
      volumes:
        - name: run-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE
          hostPath:
            path: /run/nvidia
        - name: entrypoint
          configMap:
            defaultMode: 0700
            name: specialresource-driver-container-SPECIALRESOURCE.OPENSHIFT.IO.HARDWARE-entrypoint
      nodeSelector:
        node-role.kubernetes.io/worker: ""
        SPECIALRESOURCE.OPENSHIFT.IO.NODEFEATURE: "true"
        feature.node.kubernetes.io/kernel-version.full: "SPECIALRESOURCE.OPENSHIFT.IO.KERNELVERSION"
